{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ddae065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style> body {font-family: \"Roboto Condensed Light\", \"Roboto Condensed\";} h2 {padding: 10px 12px; background-color: #E64626; position: static; color: #ffffff; font-size: 40px;} .text_cell_render p { font-size: 15px; } .text_cell_render h1 { font-size: 30px; } h1 {padding: 10px 12px; background-color: #E64626; color: #ffffff; font-size: 40px;} .text_cell_render h3 { padding: 10px 12px; background-color: #0148A4; position: static; color: #ffffff; font-size: 20px;} h4:before{ \n",
       "    content: \"@\"; font-family:\"Wingdings\"; font-style:regular; margin-right: 4px;} .text_cell_render h4 {padding: 8px; font-family: \"Roboto Condensed Light\"; position: static; font-style: italic; background-color: #FFB800; color: #ffffff; font-size: 18px; text-align: center; border-radius: 5px;}input[type=submit] {background-color: #E64626; border: solid; border-color: #734036; color: white; padding: 8px 16px; text-decoration: none; margin: 4px 2px; cursor: pointer; border-radius: 20px;}</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DATA2001 Week 4 Tutorial\n",
    "# Material last updated: 14 Mar 2023\n",
    "# Note: this notebook was designed with the Roboto Condensed font, which can be installed here: https://www.1001fonts.com/roboto-condensed-font.html\n",
    "\n",
    "from IPython.display import HTML\n",
    "HTML('''\n",
    "    <style> body {font-family: \"Roboto Condensed Light\", \"Roboto Condensed\";} h2 {padding: 10px 12px; background-color: #E64626; position: static; color: #ffffff; font-size: 40px;} .text_cell_render p { font-size: 15px; } .text_cell_render h1 { font-size: 30px; } h1 {padding: 10px 12px; background-color: #E64626; color: #ffffff; font-size: 40px;} .text_cell_render h3 { padding: 10px 12px; background-color: #0148A4; position: static; color: #ffffff; font-size: 20px;} h4:before{ \n",
    "    content: \"@\"; font-family:\"Wingdings\"; font-style:regular; margin-right: 4px;} .text_cell_render h4 {padding: 8px; font-family: \"Roboto Condensed Light\"; position: static; font-style: italic; background-color: #FFB800; color: #ffffff; font-size: 18px; text-align: center; border-radius: 5px;}input[type=submit] {background-color: #E64626; border: solid; border-color: #734036; color: white; padding: 8px 16px; text-decoration: none; margin: 4px 2px; cursor: pointer; border-radius: 20px;}</style>\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9424826",
   "metadata": {},
   "source": [
    "# Week 4 - Declarative Data Analysis with SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50e853e",
   "metadata": {},
   "source": [
    "Welcome back to Jupyter notebooks! We'll be using the same dataset as last time (with one extra small table), with three new aims:\n",
    "1. Attempting to query our localhost server without needing to go through pgAdmin\n",
    "2. Extending our SQL skills with some tougher questions\n",
    "3. A few advanced tasks aimed at those in DATA2901, but open to all to attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e656f2",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ca0d0a",
   "metadata": {},
   "source": [
    "The following cells assume that Week 3's tutorial was completed on the same device without issue. If this is not the case, make sure you revisit last week's exercises, and set up your localhost database accordingly.\n",
    "\n",
    "Accessing a PostgreSQL database from within Python requires the `psycopg2` and `sqlalchemy` modules, which can be installed on your personal machine (e.g. executing **`pip3 install psycopg2`** in a command line window). Other packages used are for dataframe results (`pandas`) or dealing with the credentials file (`json` and `os`).\n",
    "\n",
    "Download the **Credentials.json** file from Canvas, and edit the file to contain the database credentials you established last week. Ensure it exists in the same directory as this notebook (or adjust the \"credentials\" line in the code chunk below to reference the correct location). Storing the credentials separately allows notebooks to be shared between users without security concerns, and allows multiple credentials to be stored without greatly modifying the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90655c85",
   "metadata": {},
   "source": [
    "### 1.1 Connect to the Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cdc0d4",
   "metadata": {},
   "source": [
    "With these packages installed, we can load in the credentials from the JSON file, and use the helper function below to establish a connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f96ed19",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'psycopg2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/qc/f590jwm95bvcl9_hn48g3y700000gn/T/ipykernel_6580/3679858624.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msqlalchemy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_engine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpsycopg2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpsycopg2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'psycopg2'"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "credentials = \"Credentials.json\"\n",
    "\n",
    "def pgconnect(credential_filepath, db_schema=\"public\"):\n",
    "    with open(credential_filepath) as f:\n",
    "        db_conn_dict = json.load(f)\n",
    "        host       = db_conn_dict['host']\n",
    "        db_user    = db_conn_dict['user']\n",
    "        db_pw      = db_conn_dict['password']\n",
    "        default_db = db_conn_dict['user']\n",
    "        try:\n",
    "            db = create_engine('postgresql+psycopg2://'+db_user+':'+db_pw+'@'+host+'/'+default_db, echo=False)\n",
    "            conn = db.connect()\n",
    "            print('Connected successfully.')\n",
    "        except Exception as e:\n",
    "            print(\"Unable to connect to the database.\")\n",
    "            print(e)\n",
    "            db, conn = None, None\n",
    "        return db,conn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304c527d",
   "metadata": {},
   "source": [
    "Running this should successfully connect to the database. If an error is reached, double check your credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82baab83",
   "metadata": {},
   "outputs": [],
   "source": [
    "db, conn = pgconnect(credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e669ddb",
   "metadata": {},
   "source": [
    "### 1.2 Explore the Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160aba93",
   "metadata": {},
   "source": [
    "The SQLAlchemy package allows us to inspect the schema before executing queries. For example, we can see the 'NSWFuel' schema we created last week, along with any other schemas in our database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bce8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import inspect\n",
    "inspect(db).get_schema_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4263347",
   "metadata": {},
   "source": [
    "We can narrow down and find all table names from within a given schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cd2889",
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect(db).get_table_names(schema='nswfuel')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83a3221",
   "metadata": {},
   "source": [
    "**Task: Return column level information for a selected table.**\n",
    "\n",
    "Using the code examples above for tables and schemas, and the [SQLAlchemy documentation](https://docs.sqlalchemy.org/en/14/core/reflection.html), choose one of the tables listed above (e.g. \"Observations\"), and return information about all columns in the table (this is perhaps not as easy as it first seems!). What attributes are returned?\n",
    "\n",
    "Your tutor will give you a couple minutes to attempt this while they help troubleshoot people's connection problems from Section 1.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e570ee1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3181a5a",
   "metadata": {},
   "source": [
    "### 1.3 Establish Simple Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2c2749",
   "metadata": {},
   "source": [
    "The simplest way to query using Python involves the `.execute()` function on the connection object we established in Section 1.1. For a simple example, we're best to set the search_path to our NSWFuel schema from last week. The code below achieves this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4942f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(\"set search_path to NSWFuel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69a8eaf",
   "metadata": {},
   "source": [
    "With the search_path now set, let's try executing a simple query, returning the number of rows in the Fuel table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4088152f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(\"select count(*) from Fuel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4236f33",
   "metadata": {},
   "source": [
    "As seen above, the output from a simple execute function requires further unpacking. For this purpose, we'll leverage the helper function below, which produces all output as a Pandas dataframe by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002a58c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(conn, sqlcmd, args=None, df=True):\n",
    "    result = pd.DataFrame() if df else None\n",
    "    try:\n",
    "        if df:\n",
    "            result = pd.read_sql_query(sqlcmd, conn, params=args)\n",
    "        else:\n",
    "            result = conn.execute(sqlcmd, args).fetchall()\n",
    "            result = result[0] if len(result) == 1 else result\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered: \", e, sep='\\n')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27cebe8",
   "metadata": {},
   "source": [
    "Let's test it by printing out the full Fuel table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8597613b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query(conn, \"select * from Fuel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f40f833",
   "metadata": {},
   "source": [
    "Similarly verifying the count statement now produces intended output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bdefe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query(conn, \"select count(*) from Fuel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e252da",
   "metadata": {},
   "source": [
    "Or, if a Pandas dataframe is not required, we can switch it off:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7cb8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query(conn, \"select count(*) from Fuel\", df=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5624886",
   "metadata": {},
   "source": [
    "## 2. Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec930c31",
   "metadata": {},
   "source": [
    "With our connection to the database now established, we can entirely reshape or populate schemas at will. Last week the data was populated through either loading each CSV file individually, or using a mammoth SQL file containing tens of thousands of 'insert' commands. This week, we'll reload a table or two directly from a CSV, to show that we can also do so through Python.\n",
    "\n",
    "For this section, download the **raw data CSV files** from Canvas in the Week 3 Tutorial section (if you don't already have them on your computer) and store them in the same directory as this file. We'll only need the `Fuel.csv` and `Trips.csv` for the examples below, but all are provided in case you'd like further practice at populating them directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a412128e",
   "metadata": {},
   "source": [
    "### 2.1 Table Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860e84c8",
   "metadata": {},
   "source": [
    "First, we'll drop the Fuel table from last week, and redefine it using the same code that brought it to life last week. The simple `.execute()` function will suffice for this, given we aren't looking for any output, and note it can handle multiple separate queries at once (distinguished by semicolons).\n",
    "\n",
    "From there, we'll use the helper function to print all rows from the Fuel table, and confirm it is now empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bca84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(\"\"\"\n",
    "DROP TABLE IF EXISTS Fuel;\n",
    "CREATE TABLE Fuel(\n",
    "   Fuel VARCHAR(3) PRIMARY KEY,\n",
    "   Name VARCHAR(50),\n",
    "   MainComponent VARCHAR(50)\n",
    ");\"\"\")\n",
    "query(conn, \"select * from Fuel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052c8e17",
   "metadata": {},
   "source": [
    "It's worth noting that **case sensitivity** can prove problematic with data ingestion. PostgreSQL interprets many commands as lower case by default, which you can see above - the output returns lowercase column names despite the \"create table\" code containing capitalised column names. Consequentially, you'll note below that an extra line exists in cells that read in data that converts all CSV column headers to lower case, and some code blocks below may occasionally refer to tables in lower case (though it is generally not an issue for `select * from x` queries).\n",
    "\n",
    "It's also important that CSV header lines have no spaces or quotes in its column titles. Pandas might be fine to read it, but not the `.execute()` function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846193a5",
   "metadata": {},
   "source": [
    "### 2.2 Table Population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849fa0d5",
   "metadata": {},
   "source": [
    "With the CSV files in the same directory as this notebook, run the code below to read in the Fuel file as a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781212dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fueldata = pd.read_csv('Fuel.csv')\n",
    "fueldata.columns = map(str.lower, fueldata.columns)\n",
    "fueldata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f605f3d9",
   "metadata": {},
   "source": [
    "From there, loading to the database is made quite easy with Pandas! The `.to_sql()` function below populates the Fuel table with the Pandas dataframe, ignoring the index, and appending rows if the table already exists. We can then use our helper function to confirm the data was loaded successfully:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034b7d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "fueldata.to_sql(\"fuel\", con=conn, if_exists='append', index=False)\n",
    "query(conn, \"select * from Fuel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dcb060",
   "metadata": {},
   "source": [
    "It's worth mentioning the below cell, which was an important matter for previous cohorts, and doesn't hurt to recommend as a matter of best practice.\n",
    "\n",
    "The connection we established to our localhost server can be **closed** when we're done. In previous year, each student has a limit of 5 connections across all platforms to their database instance, so forgetting to close them when finished created a few \"too many connections\" headaches. Thankfully with localhost access, these are shut automatically when we terminate the notebook, and the limit is much larger. All active connections can be viewed in the pgAdmin app dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec1d504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are intentionally commented out for now given we're not done - but just worth bringing your attention to!\n",
    "\n",
    "#conn.close()\n",
    "#db.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666681ae",
   "metadata": {},
   "source": [
    "#### The Ultimate 7-Eleven Pilgrimage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5205ff9d",
   "metadata": {},
   "source": [
    "Our new \"Trips\" dataset contains the *essential* information for three potential road-trips - one north, one south, and one west...all revolving around 7-Eleven stores. It details, on each highway, in what order what stations would be reached, and how far they are apart."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649ebd7a",
   "metadata": {},
   "source": [
    "**TASK: Develop schema and populate new table.**\n",
    "\n",
    "Investigate the CSV file and determine an appropriate schema for this new table. Proceed to load the data in as a \"Trips\" table, and print its contents to confirm it has been loaded successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7df7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88eeb408",
   "metadata": {},
   "source": [
    "## 3. Querying Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f96986f",
   "metadata": {},
   "source": [
    "The remainder of today's tutorial consists of grinding through a number of SQL tasks. A quick word before that - using **triple quotes for multi-line strings** are a nice way to allow proper query formatting, while still leveraging our helper function from before to execute SQL statements.\n",
    "\n",
    "One of the only things to be aware of with this involve Python syntax semantics. For example, the `%` sign is reserved in Python strings for formatting, and so it must be escaped by using a double `%%`.\n",
    "\n",
    "The code below demonstrates this, by returning a count of stations beginning with \"7-Eleven\". In SQL, this would typically be written as `like '7-Eleven%'`, however to work with Python, this has been made into a double `%%`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb3a0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "select count(*) from Stations where servicestationname like '7-Eleven%%'\n",
    "\"\"\"\n",
    "query(conn, sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f9b00b",
   "metadata": {},
   "source": [
    "### 3.1 Simple Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c93109",
   "metadata": {},
   "source": [
    "**a) Return all stations where the company is 7-Eleven, and the address contains one of the three highways.**\n",
    "\n",
    "Recall that the three highways are \"[Princes](https://www.google.com/maps/dir/7-Eleven+Arncliffe/7-Eleven+Allawah/7-eleven+Kirrawee/7-Eleven+Sutherland/7-Eleven+Sutherland/7-Eleven+Corrimal/7-Eleven+Unanderra/7-Eleven+Dapto,+Fowles+Rd,+Dapto+NSW/7-Eleven+Albion+Park+Rail+South/7-Eleven+Albion+Park+Rail/@-34.3492607,150.6774835,10z/data=!3m1!4b1!4m62!4m61!1m5!1m1!1s0x6b12b097891c5403:0x15925d25c6350e8a!2m2!1d151.1525403!2d-33.9342447!1m5!1m1!1s0x6b12b9c85ad3bb55:0x2c809baa7d46a79a!2m2!1d151.1190974!2d-33.9804519!1m5!1m1!1s0x6b12c7c4cc63cc33:0xcd272321953787d0!2m2!1d151.076757!2d-34.031571!1m5!1m1!1s0x6b12c76f290cc3e3:0xf6172e59c904f137!2m2!1d151.0759089!2d-34.0323709!1m5!1m1!1s0x6b12c74600546a8b:0xb3aacb5a7bbf25f3!2m2!1d151.058955!2d-34.0298148!1m5!1m1!1s0x6b131eda9d82ca53:0xf260f59dec17a287!2m2!1d150.8976791!2d-34.3698968!1m5!1m1!1s0x6b1310a875f0eb1f:0x602e2abb4819b02c!2m2!1d150.8492619!2d-34.4501833!1m5!1m1!1s0x6b131194b2878043:0x5b257dfd97deffc1!2m2!1d150.7913356!2d-34.4986616!1m5!1m1!1s0x6b1312607e62e65b:0x5421e66b899436a1!2m2!1d150.7898191!2d-34.5535176!1m5!1m1!1s0x6b1312f4f1ed1505:0xff2796ec2e4d6fd3!2m2!1d150.7936141!2d-34.5589467!3e0)\", \"[Pacific](https://www.google.com/maps/dir/7-Eleven+Artarmon,+477+Pacific+Hwy,+Artarmon+NSW+2064/7-Eleven+Roseville,+Corner+Pacific+Hwy+%26,+Boundary+St,+Roseville+NSW+2069/7-Eleven+Lindfield,+238+Pacific+Hwy,+Lindfield+NSW+2070/7-Eleven+Killara,+494+Pacific+Hwy,+Killara+NSW+2071/7-Eleven+Turramurra,+1408+Pacific+Hwy,+Turramurra+NSW+2074/7-Eleven+Wahroonga,+1579+Pacific+Hwy+%26+cnr+Redleaf+Av,+Wahroonga+NSW+2076/7-Eleven+Berowra,+965-969+Pacific+Hwy+%26,+Waratah+Rd,+Berowra+NSW+2081/7-Eleven+Lisarow,+911+Pacific+Hwy,+Lisarow+NSW+2250/7-Eleven+Wyong,+156+Pacific+Hwy,+Wyong+NSW+2259/7-Eleven+Wadalba,+1+London+Dr,+Wyong+NSW+2259/7-Eleven+Marks+Point,+770+Pacific+Highway+%26,+Marks+Point+NSW+2280/7-Eleven+Belmont+North,+378+Pacific+Hwy,+Belmont+North+NSW+2280/7-Eleven+Gateshead,+13-15+Pacific+Hwy,+Gateshead+NSW+2290/7-Eleven+Heatherbrae,+369+Pacific+Hwy,+Heatherbrae+NSW+2324/@-33.3162292,150.8352557,9z/data=!3m1!4b1!4m85!4m84!1m5!1m1!1s0x6b12af28531b53d1:0x7ca308f31c1fd123!2m2!1d151.177424!2d-33.8104872!1m5!1m1!1s0x6b12a8da47dca7bf:0x389d71b2ef1ca8ec!2m2!1d151.1796121!2d-33.787646!1m5!1m1!1s0x6b12a8c1f98e41ad:0x30bf2d00f3ce17d4!2m2!1d151.1690677!2d-33.778887!1m5!1m1!1s0x6b12a894f81389db:0xf017d68f9f31be0!2m2!1d151.1608!2d-33.7713459!1m5!1m1!1s0x6b12a7c50fd8ba19:0xbd1edc7dee5a1313!2m2!1d151.1264195!2d-33.7330427!1m5!1m1!1s0x6b12a794d5761e7f:0x6eb25bc7378bc3cd!2m2!1d151.1168423!2d-33.7197916!1m5!1m1!1s0x6b0d50acc506c033:0x7506a8b8a4986de0!2m2!1d151.148044!2d-33.6267941!1m5!1m1!1s0x6b72cb090b2e2b4b:0xe40fe4282da66380!2m2!1d151.3653485!2d-33.3854798!1m5!1m1!1s0x6b72d1fa366aa0d7:0x6311d7a4d152f474!2m2!1d151.4292966!2d-33.2743712!1m5!1m1!1s0x6b72d1ba840bee81:0xa684d0780b01c4ed!2m2!1d151.4547562!2d-33.2646063!1m5!1m1!1s0x6b7323aad6054ff3:0xf0d76668bf2ffd09!2m2!1d151.6534208!2d-33.0566119!1m5!1m1!1s0x6b7322d1c9bee475:0x57007ccbf0d12e24!2m2!1d151.6642304!2d-33.0228048!1m5!1m1!1s0x6b733d7bb7dbcadf:0xe5871a5bd3e20a9d!2m2!1d151.6918568!2d-32.9873444!1m5!1m1!1s0x6b736a22bf53fa87:0x10c45319c8af4a41!2m2!1d151.7254309!2d-32.7913428)\" or \"[Great Western](https://www.google.com/maps/dir/7-Eleven+Greystanes/7-Eleven+Eastern+Creek/7-Eleven+Minchinbury/7-Eleven+Minchinbury/7-Eleven+Colyton/7-Eleven+Werrington+South/7-Eleven+Kingswood/7-Eleven+Emu+Plains/7-Eleven+Blaxland/7-Eleven+Lithgow/@-33.5923961,150.490052,10.11z/data=!4m62!4m61!1m5!1m1!1s0x6b1299023bba65b9:0x63d4057c8f33bd10!2m2!1d150.9359341!2d-33.8085628!1m5!1m1!1s0x6b129a055c1df8ff:0x441541b06cc1f486!2m2!1d150.8496248!2d-33.7880988!1m5!1m1!1s0x6b129a7aecbfa6e3:0x87b23f69c5cba53e!2m2!1d150.8286577!2d-33.7821321!1m5!1m1!1s0x6b129a85d090a989:0x5db9c22ca1305cca!2m2!1d150.8081157!2d-33.7782696!1m5!1m1!1s0x6b129a98f5a1f5ef:0xadc7b8627f77efce!2m2!1d150.7935692!2d-33.7751205!1m5!1m1!1s0x6b128585420a816f:0x682e2b2d1121f011!2m2!1d150.7568147!2d-33.7676798!1m5!1m1!1s0x6b1285794ab43efd:0x3c69e835c6b53f59!2m2!1d150.7265282!2d-33.7597829!1m5!1m1!1s0x6b1285fde89769db:0xaeb31d48020e374a!2m2!1d150.6762167!2d-33.7465279!1m5!1m1!1s0x6b12886e2a3c4199:0x34af2dccaecf9a22!2m2!1d150.613479!2d-33.7464473!1m5!1m1!1s0x6b120a37395caea5:0xdc2e8bb3f8bee6cc!2m2!1d150.1369233!2d-33.4802074!3e0)\". Choose whichever is more appealing to your idea of a road trip!\n",
    "\n",
    "*(also feel free to compare your results to the Google Maps links above to confirm your output)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf4d03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb66080f",
   "metadata": {},
   "source": [
    "**b) Return all 7-Eleven stations on your chosen route, in order of when you come across them.**\n",
    "\n",
    "The order is defined by the \"Stop\" column in the Trips table. Try inner joining this to the Stations table, and providing only the following columns: (stop, servicestationname, address, minutes, kilometres)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b11934",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373e0b98",
   "metadata": {},
   "source": [
    "### 3.2 Grouped Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6b169d",
   "metadata": {},
   "source": [
    "**a) Using only the Trips table, print the total time, distance, and average speed of each highway journey.**\n",
    "\n",
    "Recall that speed is calculated as distance/time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2646df7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecf248b",
   "metadata": {},
   "source": [
    "**b) For your selected highway journey, which station has the most unique dates for which observations were made?**\n",
    "\n",
    "List all stations in descending order of number of dates recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e314c664",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88d8990",
   "metadata": {},
   "source": [
    "**c) For your selected highway journey, AND a selected fuel type, what are the minimum and maximum prices of fuel recorded at each station?**\n",
    "\n",
    "e.g. use FuelCode = 'P98', and if possible, return the result in the correct arrival order for your trip (using the \"Stop\" column again).\n",
    "\n",
    "Do prices differ significantly? Is there a particular station that would be most worthwhile fuelling up at?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c63a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a75457a",
   "metadata": {},
   "source": [
    "### 3.3a DATA2001: Investigation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030c3fff",
   "metadata": {},
   "source": [
    "**If time allows:** Consider what other simple analytic questions about the data we have would be worthwhile investigating. Construct a question of your own choosing and complete it below - if there's time we'll get to share some interesting findings from across the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c250319",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c648927b",
   "metadata": {},
   "source": [
    "### 3.3b DATA2901: Advanced Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0876e536",
   "metadata": {},
   "source": [
    "The following queries are of greater difficulty and **intended only for the advanced stream DATA2901**.\n",
    "\n",
    "That being said, all data enthusiasts are invited to grapple with the tasks below! You're even welcome to return to these in a week or two once your SQL confidence has grown, and/or solutions are available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21369f1a",
   "metadata": {},
   "source": [
    "**a) Return the five statistical values needed for multiple Tukey boxplots, for each day of the week, made on your selected highway / fuel type.**\n",
    "\n",
    "e.g. for E10 on the \"Great Western\", return the minimum price, maximum price, and three quartiles in between for each day of the week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1eb9221",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ea89f4",
   "metadata": {},
   "source": [
    "**b) Are there any outliers for the price of your selected fuel/highway on a given weekday?**\n",
    "\n",
    "e.g. on Tuesdays, E10 on the Great Western Highway has a Q1 of 178.80 and a Q3 of 195.90. Outliers are statistically defined as being below $Q_1 - 1.5 \\times (Q_3-Q_1)$ or above $Q_3 + 1.5 \\times (Q_3-Q_1)$. Do any such observations exist?\n",
    "\n",
    "Note this query is best done by using your result from part a) as a subquery. Try starting with the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0552d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO\n",
    "sql = \"\"\"\n",
    "with quartiles as (\n",
    "  /* PART (A) SOLUTION */\n",
    ")\n",
    "\n",
    "select /* PART (B) SOLUTION LEVERAGING THIS */\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38eb493",
   "metadata": {},
   "source": [
    "**c) For prices made in the same observation, is there any correlation between E10 and P98 prices?**\n",
    "\n",
    "Hint: The `corr()` SQL function can be used to find the statistical correlation between two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbda131",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce13e0e6",
   "metadata": {},
   "source": [
    "All done! Time to close those connections - enjoy your week :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290e7339",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()\n",
    "db.dispose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
