{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acaba84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style> body {font-family: \"Roboto Condensed Light\", \"Roboto Condensed\";} h2 {padding: 10px 12px; background-color: #E64626; position: static; color: #ffffff; font-size: 40px;} .text_cell_render p { font-size: 15px; } .text_cell_render h1 { font-size: 30px; } h1 {padding: 10px 12px; background-color: #E64626; color: #ffffff; font-size: 40px;} .text_cell_render h3 { padding: 10px 12px; background-color: #0148A4; position: static; color: #ffffff; font-size: 20px;} h4:before{ \n",
       "    content: \"@\"; font-family:\"Wingdings\"; font-style:regular; margin-right: 4px;} .text_cell_render h4 {padding: 8px; font-family: \"Roboto Condensed Light\"; position: static; font-style: italic; background-color: #FFB800; color: #ffffff; font-size: 18px; text-align: center; border-radius: 5px;}input[type=submit] {background-color: #E64626; border: solid; border-color: #734036; color: white; padding: 8px 16px; text-decoration: none; margin: 4px 2px; cursor: pointer; border-radius: 20px;}</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DATA2001 Week 9 Tutorial\n",
    "# Material last updated: 26 Apr 2023\n",
    "# Note: this notebook was designed with the Roboto Condensed font, which can be installed here: https://www.1001fonts.com/roboto-condensed-font.html\n",
    "\n",
    "from IPython.display import HTML\n",
    "HTML('''\n",
    "    <style> body {font-family: \"Roboto Condensed Light\", \"Roboto Condensed\";} h2 {padding: 10px 12px; background-color: #E64626; position: static; color: #ffffff; font-size: 40px;} .text_cell_render p { font-size: 15px; } .text_cell_render h1 { font-size: 30px; } h1 {padding: 10px 12px; background-color: #E64626; color: #ffffff; font-size: 40px;} .text_cell_render h3 { padding: 10px 12px; background-color: #0148A4; position: static; color: #ffffff; font-size: 20px;} h4:before{ \n",
    "    content: \"@\"; font-family:\"Wingdings\"; font-style:regular; margin-right: 4px;} .text_cell_render h4 {padding: 8px; font-family: \"Roboto Condensed Light\"; position: static; font-style: italic; background-color: #FFB800; color: #ffffff; font-size: 18px; text-align: center; border-radius: 5px;}input[type=submit] {background-color: #E64626; border: solid; border-color: #734036; color: white; padding: 8px 16px; text-decoration: none; margin: 4px 2px; cursor: pointer; border-radius: 20px;}</style>\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64a0632",
   "metadata": {},
   "source": [
    "# Week 9 - Spatial Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3112a22",
   "metadata": {},
   "source": [
    "This week's tutorial extends beyond the world of simple data types and into the realm of **geo-spatial data**. Today we'll be covering the basic types, how to ingest it from different sources (shape files, geoJSON, web APIs) and then querying it in PostGIS - a spatial database extension for PostgreSQL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56eb01ba",
   "metadata": {},
   "source": [
    "## 1. Introduction to Spatial Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a356b1eb",
   "metadata": {},
   "source": [
    "While geospatial data can exist in many forms (e.g. just 'latitude' and 'longitude' fields technically constitute spatial information), the **shapefile** is the most common data format for geographic information. It is a complex format, often involving multiple files. We've provided a simple \"world\" shapefile containing basic shapes of most international countries, which contains the following files:\n",
    "\n",
    "| file | purpose |\n",
    "| :--- | :--- |\n",
    "| world.shp | the feature geometry itself |\n",
    "| world.shx | positional indexes to speed things up |\n",
    "| world.dbf | the other attributes |\n",
    "\n",
    "These are just some of many other files that together can comprise a shapefile - see the [wiki](https://en.wikipedia.org/wiki/Shapefile) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a57d7f",
   "metadata": {},
   "source": [
    "### 1.1 Shapefiles and Polygons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a4065c",
   "metadata": {},
   "source": [
    "Firstly, we'll have to leverage a couple new packages.\n",
    "- Pandas has an extension named **GeoPandas**, intended for querying spatial data\n",
    "- **Shapely** is a crucial package for interpreting and manipulating geometries\n",
    "- **Geoalchemy** is a support library for SQLAlchemy (which we've used before), allowing spatial databases\n",
    "\n",
    "Install these as per usual in your command line window (e.g. `pip3 install geopandas`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40f0c0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon\n",
    "from geoalchemy2 import Geometry, WKTElement\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd6f0a6",
   "metadata": {},
   "source": [
    "Loading in the shapefile is quite simple when done through GeoPandas, working much like Pandas reads in CSVs.\n",
    "\n",
    "Note the cell below assumes the `data.zip` has been downloaded from Canvas, and unpacked in the same directory as this notebook (i.e. there exists a 'data' folder containing the shapefile folders).\n",
    "\n",
    "Note that the types in the geometry column are **polygons** and **multipolygons**. These reference full shapes - other simpler spatial data types include lines, points, etc. See the [ArcGIS docs](https://help.arcgis.com/en/geodatabase/10.0/sdk/arcsde/concepts/geometry/shapes/types.htm) for more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09c354e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "DriverError",
     "evalue": "world/world.shp: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32mfiona/ogrext.pyx\u001b[0m in \u001b[0;36mfiona.ogrext.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfiona/_err.pyx\u001b[0m in \u001b[0;36mfiona._err.exc_wrap_pointer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m: world/world.shp: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDriverError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/qc/f590jwm95bvcl9_hn48g3y700000gn/T/ipykernel_67903/3487004265.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcountries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"world/world.shp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcountries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/geopandas/io/file.py\u001b[0m in \u001b[0;36m_read_file\u001b[0;34m(filename, bbox, mask, rows, engine, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"fiona\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         return _read_file_fiona(\n\u001b[0m\u001b[1;32m    260\u001b[0m             \u001b[0mpath_or_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/geopandas/io/file.py\u001b[0m in \u001b[0;36m_read_file_fiona\u001b[0;34m(path_or_bytes, from_bytes, bbox, mask, rows, where, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfiona_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m             \u001b[0mcrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrs_wkt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0;31m# attempt to get EPSG code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/fiona/env.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0menv_ctor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/fiona/__init__.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt, allow_unsupported_drivers, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             colxn = Collection(\n\u001b[0m\u001b[1;32m    337\u001b[0m                 \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/fiona/collection.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode, driver, schema, crs, encoding, layer, vsi, archive, enabled_drivers, crs_wkt, ignore_fields, ignore_geometry, include_fields, wkt_version, allow_unsupported_drivers, **kwargs)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWritingSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mfiona/ogrext.pyx\u001b[0m in \u001b[0;36mfiona.ogrext.Session.start\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfiona/ogrext.pyx\u001b[0m in \u001b[0;36mfiona.ogrext.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mDriverError\u001b[0m: world/world.shp: No such file or directory"
     ]
    }
   ],
   "source": [
    "countries = gpd.read_file(\"world/world.shp\")\n",
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc193908",
   "metadata": {},
   "source": [
    "#### How many countries are there?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289d758d",
   "metadata": {},
   "source": [
    "A dataset like this is the perfect segue to a data quality discussion, and the semantics of definitions. While some countries are clearly missing, what would be considered a **complete** dataframe here? For those interested, [this video](https://www.youtube.com/watch?v=4AivEQmfPpk) unpacks how difficult it is to answer the true number of countries (the most wholesome example is probably Kosovo, who aren't universally recognised as an independent country, and have a [website](https://www.kosovothanksyou.com/) to thank those who consider it a legitimate state!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebdaa13",
   "metadata": {},
   "source": [
    "### 1.2 Geopandas Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b638c5",
   "metadata": {},
   "source": [
    "Another dataset provided on Canvas contains capital cities across the world, provided by [SimpleMaps](https://simplemaps.com/data/world-cities). This is a simple CSV, containing the latitude and longitude coordinates of each city, as well as a population estimate, and the type of capital it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63600f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = pd.read_csv('Capitals.csv')\n",
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12e3081",
   "metadata": {},
   "source": [
    "We can leverage GeoPandas' `.points_from_xy()` function to properly store a geographical point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89b3085",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities['geom'] = gpd.points_from_xy(cities.lng, cities.lat)  # creating the geometry column\n",
    "cities = cities.drop(columns=['lat', 'lng'])  # removing the old latitude/longitude fields\n",
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a9fc8d",
   "metadata": {},
   "source": [
    "## 2. Loading Spatial Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affb0171",
   "metadata": {},
   "source": [
    "Loading the information into Pandas dataframes is a useful start, but to begin forming queries, we must ingest the data into our SQL databases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c213c15",
   "metadata": {},
   "source": [
    "### 2.1 Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ce3ddc",
   "metadata": {},
   "source": [
    "The below functions are taken directly from the Week 4 tutorial. Remember this requires a `Credentials.json` file to exist in the same directory as this notebook, as was needed in previous weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875a26db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import json\n",
    "\n",
    "credentials = \"Credentials.json\"\n",
    "\n",
    "def pgconnect(credential_filepath, db_schema=\"public\"):\n",
    "    with open(credential_filepath) as f:\n",
    "        db_conn_dict = json.load(f)\n",
    "        host       = db_conn_dict['host']\n",
    "        db_user    = db_conn_dict['user']\n",
    "        db_pw      = db_conn_dict['password']\n",
    "        default_db = db_conn_dict['user']\n",
    "        try:\n",
    "            db = create_engine('postgresql+psycopg2://'+db_user+':'+db_pw+'@'+host+'/'+default_db, echo=False)\n",
    "            conn = db.connect()\n",
    "            print('Connected successfully.')\n",
    "        except Exception as e:\n",
    "            print(\"Unable to connect to the database.\")\n",
    "            print(e)\n",
    "            db, conn = None, None\n",
    "        return db,conn\n",
    "\n",
    "def query(conn, sqlcmd, args=None, df=True):\n",
    "    result = pd.DataFrame() if df else None\n",
    "    try:\n",
    "        if df:\n",
    "            result = pd.read_sql_query(sqlcmd, conn, params=args)\n",
    "        else:\n",
    "            result = conn.execute(sqlcmd, args).fetchall()\n",
    "            result = result[0] if len(result) == 1 else result\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered: \", e, sep='\\n')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a416aa",
   "metadata": {},
   "source": [
    "The below cell actually connects to the database - should you reach errors, check your credentials file, ensure you're using the VPN, and consult the [FAQ thread on Ed](https://edstem.org/au/courses/8139/discussion/769731)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7734dbdf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pgconnect' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/qc/f590jwm95bvcl9_hn48g3y700000gn/T/ipykernel_67903/294008973.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpgconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pgconnect' is not defined"
     ]
    }
   ],
   "source": [
    "db, conn = pgconnect(credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c409b30e",
   "metadata": {},
   "source": [
    "Note the functions we'll be leveraging for geographical operations rely on PostGIS (the spatial extension to PostgreSQL) being installed on the database - the below query confirms it is correctly configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b46aeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "query(conn, \"select PostGIS_Version()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0068757",
   "metadata": {},
   "source": [
    "### 2.2 SRID Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6722bd05",
   "metadata": {},
   "source": [
    "Ensuring the spatial data types from GeoPandas are the same as those expected by PostGIS requires conversion to the **Well-Known Text (WKT)** format, as an intermediate step. This can be done using the `geoalchemy2` library, to convert from the `shapely` types in GeoPandas to the WKT format in PostGIS.\n",
    "\n",
    "We'll also be sure to specify the **Spatial Reference Identifier (SRID)** - in this case 4326, to represent the [WGS84 world geodetic coordinate system](https://en.wikipedia.org/wiki/World_Geodetic_System) used by our example data set. The following code simply converts the 'geom' column of the **Cities** dataframe accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfef394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "srid = 4326\n",
    "cities['geom'] = cities['geom'].apply(lambda x: WKTElement(x.wkt, srid=srid))\n",
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f394c41",
   "metadata": {},
   "source": [
    "Converting the polygons in our **Countries** dataframe requires more work. We'll first ensure they're all represented as multipolygons (of which polygons are a subset), and then conduct the same WKT conversion, all using a simple helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5cb423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wkt_element(geom, srid):\n",
    "    if geom.geom_type == 'Polygon':\n",
    "        geom = MultiPolygon([geom])\n",
    "    return WKTElement(geom.wkt, srid)\n",
    "\n",
    "countriesog = countries.copy()  # creating a copy of the original for later\n",
    "countries['geom'] = countries['geometry'].apply(lambda x: create_wkt_element(geom=x,srid=srid))  # applying the function\n",
    "countries = countries.drop(columns=\"geometry\")  # deleting the old copy\n",
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a74ca2",
   "metadata": {},
   "source": [
    "### 2.3 Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90a484b",
   "metadata": {},
   "source": [
    "Let's proceed to populate tables in our database, firstly by defining schemas for each. Note the SRID is referenced in the geometry columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a13337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(\"\"\"\n",
    "DROP TABLE IF EXISTS cities;\n",
    "CREATE TABLE cities (\n",
    "    city VARCHAR(100), \n",
    "    population INTEGER, \n",
    "    capital VARCHAR(10),\n",
    "    geom GEOMETRY(POINT,4326)\n",
    ");\"\"\"\n",
    ")\n",
    "\n",
    "conn.execute(\"\"\"\n",
    "DROP TABLE IF EXISTS world;\n",
    "CREATE TABLE world (\n",
    "    pop_est NUMERIC, \n",
    "    continent VARCHAR(80), \n",
    "    name VARCHAR(80), \n",
    "    iso_a3 VARCHAR(80), \n",
    "    gdp_md_est NUMERIC,\n",
    "    geom GEOMETRY(MULTIPOLYGON,4326)\n",
    ");\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89eb1bd",
   "metadata": {},
   "source": [
    "With this established, we can insert the data into these tables. With spatial data, it does require our code to be explicit in our type defintions so the `geoalchemy` library can handle the conversions.\n",
    "\n",
    "Firstly, we'll test the **Cities** table (will take longer than Countries due to the containing many more rows), then the **Countries** information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335577b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.to_sql('cities', conn, if_exists='append', index=False, dtype={'geom': Geometry('POINT', srid)})\n",
    "query(conn, \"select * from cities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68393c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.to_sql(\"world\", conn, if_exists='append', index=False, dtype={'geom': Geometry('MULTIPOLYGON', srid)})\n",
    "query(conn, \"select * from world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de14a3e",
   "metadata": {},
   "source": [
    "## 3. Querying Spatial Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e01037",
   "metadata": {},
   "source": [
    "With the data now populated, we can commence with the interesting part - building queries and answering questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f61c35",
   "metadata": {},
   "source": [
    "### 3.1 Areas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf721bc",
   "metadata": {},
   "source": [
    "Let's walk through an example, by calculating the area of each region. This can be achieved using the PostGIS `ST_Area()` function. Below would therefore be a query that returns the **five largest countries in Africa**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44594ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT name AS country, ST_Area(geom) AS total_area\n",
    "FROM world\n",
    "WHERE continent='Africa'\n",
    "ORDER BY total_area DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "query(conn, sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46600f6d",
   "metadata": {},
   "source": [
    "Now there is a small catch with area calculations, which is alluded to by the low numbers returned (these reflect the geometry type and selected SRID). \n",
    "\n",
    "In order to get the size in square meters ($m^2$), we need use the **geography** type which treats polygons not as objects on a flat plane, but on a sphere, which makes them suitable for geodetic data like these world maps here. We can convert the geometries to the the GEOGRAPHY type by using `::geography` as a cast operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd12856",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT name AS country, ST_Area(geom::geography) AS total_area_m2\n",
    "FROM world\n",
    "WHERE continent='Africa'\n",
    "ORDER BY total_area_m2 DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "query(conn, sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb459f2b",
   "metadata": {},
   "source": [
    "Final minor addition if scientific notation isn't ideal - we can express this as a complete integer using a basic Pandas transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a40135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = query(conn, sql)\n",
    "results['total_area_m2'] = results['total_area_m2'].astype('int64')\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be814a1",
   "metadata": {},
   "source": [
    "### 3.2 Points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9ae82c",
   "metadata": {},
   "source": [
    "Let's consider another spatial function - `ST_Contains()`. This can be used to determine if a given point lies within a region.\n",
    "\n",
    "According to Google, the coordinates of Paris are `48.8566° N, 2.3522° E`. If we store this as a geometric point (using `ST_Point` - note the longitude comes first!) and then convert this into the SRID using `ST_SetSRID()` function, we can then see if any of the polygons in our countries dataframe contain this point. As expected, this should yield France:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0043d421",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT name\n",
    "FROM world\n",
    "WHERE ST_Contains(geom, ST_SetSRID(ST_Point(2.3, 48.86), 4326))\n",
    "\"\"\"\n",
    "query(conn, sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fe6f5d",
   "metadata": {},
   "source": [
    "**a) Find all cities within Australia**\n",
    "\n",
    "Hint: this involves using the ST functions as the *join* condition. As an extension, see if it can be achieved with multiple different spatial functions (see the [PostGIS docs for more functions](https://postgis.net/docs/reference.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8748401e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO DO\n",
    "sql = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "query(conn, sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9fea74",
   "metadata": {},
   "source": [
    "**b) List all countries that have more than two primary capital cities.**\n",
    "\n",
    "Which appears to have the most? Is this accurate? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef154819",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO DO\n",
    "sql = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "query(conn, sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf84346c",
   "metadata": {},
   "source": [
    "### 3.3 Intersections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43c1c73",
   "metadata": {},
   "source": [
    "Returning to our example of Kosovo earlier, let's see if we can determine it's neighbouring countries.\n",
    "\n",
    "We can leverage a **self-join** with the 'world' table to determine which countries share a boundary with each other. Normally, we would expect to use the `ST_Touch()` function for this, but in our dataset, the boundaries are in low-resolution, so some border shapes actually intersect. Hence the more generic `ST_Intersects()` spatial relationship function should suffice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f81b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT B.name\n",
    "FROM world A JOIN world B ON ST_Intersects(A.geom, B.geom)\n",
    "WHERE A.name = 'Kosovo' AND B.name != A.name\n",
    "\"\"\"\n",
    "query(conn, sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8f42e9",
   "metadata": {},
   "source": [
    "**a) Find all countries that neighbour Germany, ordered by the furthest north neighbour to the nearest south.**\n",
    "\n",
    "Ordering successfully will require the y-value of the centre point of a given polygon - try finding [spatial functions](https://postgis.net/docs/reference.html) to achieve this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c289e691",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO DO\n",
    "sql = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "query(conn, sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91257cda",
   "metadata": {},
   "source": [
    "**b) Find the most common city name in the dataset. Afterwards, determine which countries these cities exist in.**\n",
    "\n",
    "There are 4 'San Luis' cities - 2 in Cuba, 1 in Argentina, and 1 in Guatemala. Are any city names more common, and what countries are they found in?\n",
    "\n",
    "Spoiler: you can confirm your answer using [this Wikipedia page](https://en.wikipedia.org/wiki/List_of_cities_and_towns_in_Colombia)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab69c254",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO DO - QUERY 1\n",
    "sql = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "query(conn, sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a00804",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO DO - QUERY 2\n",
    "sql = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "query(conn, sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14f96ea",
   "metadata": {},
   "source": [
    "## 4. Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed477e4",
   "metadata": {},
   "source": [
    "Another beautiful application of spatial data involves plotting the results. No tasks here - just a brief demonstration. The below code filters the original version of the **Countries** dataframe to only countries within Europe and Asia, and then plots them using `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6e0e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "eurasia = countriesog[(countriesog['continent']=='Europe') | (countriesog['continent']=='Asia')]\n",
    "eurasia.plot(figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff7e547",
   "metadata": {},
   "source": [
    "We can achieve the same result with a combination of SQL and GeoPandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeaff04",
   "metadata": {},
   "outputs": [],
   "source": [
    "eurasia = gpd.read_postgis(\"SELECT name, geom FROM world WHERE continent='Europe' or continent='Asia'\", conn)\n",
    "eurasia.plot(figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0980f7b1",
   "metadata": {},
   "source": [
    "For an even more aesthetic result - we can add a colour palette."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c288864",
   "metadata": {},
   "outputs": [],
   "source": [
    "eurasia.plot(cmap='Set2', figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3242adfd",
   "metadata": {},
   "source": [
    "And when complete, we can export geospatial subsets as new shapefiles. The following code will create a new 'Eurasia' shapefile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888af410",
   "metadata": {},
   "outputs": [],
   "source": [
    "eurasia.to_file(\"world/eurasia.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62330ef3",
   "metadata": {},
   "source": [
    "### 4.2 API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d8d72e",
   "metadata": {},
   "source": [
    "Week 7's tutorial investigated APIs. One example included using the **OpenStreetMap API** to return details of locations. One of the functionalities offered by this platform that we didn't fully explore was the ability to extract the corresponding geospatial polygons. Let's first return to the code block we used to access the API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f949d65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time as t\n",
    "import requests\n",
    "def address_details(params, wait=5):\n",
    "    base_url = 'https://nominatim.openstreetmap.org/search'\n",
    "    t.sleep(wait)  # 5 second wait to avoid overloading (too many requests could lock out the whole uni's IP range!)\n",
    "    response = requests.get(base_url, params = params)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc6950b",
   "metadata": {},
   "source": [
    "Let's again search for the School of Computer Science, found at 1 Cleveland Street, Darlington. An additional parameter we'll pass is setting `polygon_geojson` to 1, which will return us the coordinates of it's boundaries, as seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf90113",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'q': '1 Cleveland Street, Darlington, Australia', 'limit':'1', 'format': 'json', 'polygon_geojson': '1'}\n",
    "results = address_details(parameters)\n",
    "print(results[0]['geojson']['coordinates'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6967bee",
   "metadata": {},
   "source": [
    "A couple dozen coordinates printed out isn't particularly inspiring. Seeing it plotted though, is quite beautiful. Compare the output below to the shape of the building on Google Maps - it's quite a good match!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccea186",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))  # setting up the plot\n",
    "ax.ticklabel_format(useOffset=False)  # avoiding scientific notation on the axes\n",
    "p = Polygon(results[0]['geojson']['coordinates'][0])  # taking the coordinates returned and storing them as a polygon\n",
    "x,y = p.exterior.xy  # extracting the x and y coordinates from the exterior of that polygon\n",
    "ax.plot(x,y)  # plotting them on the graph\n",
    "plt.title(\"School of Computer Science\", fontdict={'fontsize': 16}, pad=10)  # setting a title\n",
    "plt.xlabel(\"Longitude\", fontdict={'fontsize': 14}, labelpad=10)  # setting an x-axis\n",
    "plt.ylabel(\"Latitude\", fontdict={'fontsize': 14}, labelpad=10)  # setting a y-axis\n",
    "plt.show()  # displaying the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dec0892",
   "metadata": {},
   "source": [
    "#### Tutorial Complete!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e0d04d",
   "metadata": {},
   "source": [
    "Hopefully this was a useful introduction to geospatial data, which will be crucial to the group assignment. Remember to close your database connections, and enjoy your week!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec5f1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()\n",
    "db.dispose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
